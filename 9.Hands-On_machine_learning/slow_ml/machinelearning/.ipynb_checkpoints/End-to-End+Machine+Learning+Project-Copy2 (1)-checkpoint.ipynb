{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Machine Learning Project\n",
    "1. [Look at the big picture](#ch1)\n",
    "2. [Get the data](#ch2)\n",
    "3. [Discover and visualize the data to gain insights](#ch3)\n",
    "4. [Prepare the data for Machine Learning algorithms](#ch4)\n",
    "5. [Select a model and train it](#ch5)\n",
    "6. [Fine-tune your model](#ch6)\n",
    "7. [Present your solution](#ch7)\n",
    "8. [Launch, monitor, and maintain your system](#ch8)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look at the Big Picture<a id='ch1'></a>\n",
    "* Frame the Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Question | Answer |\n",
    "|:------|:------|\n",
    "| what is business objective? | your model's output will be fed to another ML system |\n",
    "| what the current solution looks like? | estimated manually by experts; costly, time-consuming and not accurate |\n",
    "| is it supervised, unsupervised, or reinforcement learning? | supervised |\n",
    "| is it a classification task or a regression task? | (multivariate) regression |\n",
    "| should I use batch learning or online learning? | batch learning |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Select a Performance Measure\n",
    "    * Performance Measures\n",
    "        * Root Mean Square Error (RMSE) : $$RMSE(X, h) = \\sqrt{\\frac{1}{m}\\sum_{i=1}^{m}(h(x^i)-y^i)^2}$$    \n",
    "$$=l_2$$\n",
    "\n",
    "        * Mean Absolute Error (MAE) : $$MAE(X, h) = \\frac{1}{m}\\sum_{i=1}^{m}\\left|(h(x^i)-y^i)\\right|$$\n",
    "$$=l_1$$\n",
    "    * Notations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Notation | What is means |\n",
    "|:------:|:------|\n",
    "| m | the number of instances in the dataset |\n",
    "| $$x^i$$| vector of all the feature values of $i^{th}$ instance |\n",
    "| $$y^i$$| label of $i^{th}$ instance |\n",
    "| $$X$$| - a matrix containing all the feature values of all instances <br> - one row per instance, <br> - the $i^{th}$ row is equal to the transpose of $x^i$, noted $(x^i)^T$ |\n",
    "| $$h$$ | - system's prediction function called hypothesis <br> - $\\hat {y}=h(x^i)$|\n",
    "| $RMSE(X,h)$| cost function measured on the set of examples using hypothesis |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "$$x^1 = \\left\\lgroup \\matrix{-118.29 \\cr 33.91 \\cr 1,416 \\cr 38,372} \\right\\rgroup$$\n",
    "\n",
    "$$y^1 = 156,400$$\n",
    "\n",
    "$$ X = \\left\\lgroup \\matrix{(x^1)^T \\cr (x^2)^T \\cr \\vdots \\cr (x^1999)^T \\cr (x^2000)^T} \\right\\rgroup \\\n",
    " = \\left\\lgroup \\matrix{-118.29 & 33.91 & 1,416 & 38,372 \\cr \\vdots & \\vdots & \\vdots & \\vdots} \\right\\rgroup $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the Data<a id='ch2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* Download the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "from six.moves import urllib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import hashlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "from skimage import io\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml/master/\"\n",
    "HOUSING_PATH = os.path.join(\"datasets\", \"housing\") # 'datasets/housing'\n",
    "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\" # DOWNLOAD_ROOT + HOUSING_PATH + \"/housing.tgz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
    "    '''\n",
    "    1. (없을 경우) 디렉토리 생성\n",
    "    2. housing.tgz 다운로드\n",
    "    3. housing.csv 추출\n",
    "    '''\n",
    "    if not os.path.isdir(housing_path): # 현재 directory에 housing_path(HOUSING_PATH => datasets/housing 존재 여부 확인)\n",
    "        os.makedirs(housing_path) # housing_path가 없을 경우 directory를 생성\n",
    "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
    "    urllib.request.urlretrieve(housing_url, tgz_path) # url => housing_url, filename => tgz_path \n",
    "    housing_tgz = tarfile.open(tgz_path)\n",
    "    housing_tgz.extractall(path=housing_path)\n",
    "    housing_tgz.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fetch_housing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_housing_data(housing_path=HOUSING_PATH):\n",
    "    csv_path = os.path.join(housing_path, \"housing.csv\") # 위에서 디렉토리 생성했으므로 확인하는 로직 생략\n",
    "    return pd.read_csv(csv_path) # dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Take a Quick Look at the Data Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "housing = load_housing_data() # dataframe을 housing이라는 variable에 저장\n",
    "housing.head() # head는 상위 n row 보여준다. default=5이지만 수동으로 변경 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "housing.info() # 교재에는 () 빠져있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "housing[\"ocean_proximity\"].value_counts() # column 단위로 적용하며 sql count & group by 와 유사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "housing.describe() # numerical data'만' 나타낸다 (null 무시)\n",
    "                   # ocean_proximity 정보가 궁금하면 housing['ocean_proximity].describe()\n",
    "                   # 보여주는 지표는 다르다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "housing.hist(bins=50, figsize=(15, 10)) # bins 설정에 따라 더 잘 드러나거나 한다\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 하한선, 상한선 설정된 raw data\n",
    "    * feature\n",
    "        * median income, housing median => 조정\n",
    "    * target\n",
    "        * 조정된 값 이상은 target이 갈 수 없다고 학습하는 문제 발생\n",
    "        * 방안 (상한선 이상의 값에 대한)\n",
    "            * 조정된 dataset 선별\n",
    "            * dataset 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_train_test(data, test_ratio):\n",
    "    shuffled_indicies = np.random.permutation(len(data)) # np.random.permutation(k) => k이하 랜덤 숫자를 k번 출력\n",
    "    test_set_size = int(len(data) * test_ratio)\n",
    "    test_indices = shuffled_indicies[:test_set_size]\n",
    "    train_indices = shuffled_indicies[test_set_size:]\n",
    "    return data.iloc[train_indices], data.iloc[test_indices] # tuple 형태로 train_set, test_set 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set, test_set = split_train_test(housing, 0.2)\n",
    "print(len(train_set), \"train +\", len(test_set), \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_set_check(identifier, test_ratio, hash):\n",
    "    return hash(np.int64(identifier)).digest()[-1] < 256 * test_ratio\n",
    "\n",
    "def split_train_test_by_id(data, test_ratio, id_column, hash=hashlib.md5):\n",
    "    ids = data[id_column]\n",
    "    in_test_set = ids.apply(lambda id_: test_set_check(id_, test_ratio, hash))\n",
    "    return data.loc[~in_test_set], data.loc[in_test_set]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* loc :  works on labels in the index.\n",
    "* iloc : works on the positions in the index (so it only takes integers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "housing_with_id = housing.reset_index()\n",
    "train_set, test_set = split_train_test_by_id(housing_with_id, 0.2, 'index') # index column 사용\n",
    "print(len(train_set), \"train +\", len(test_set), \"test\") # 주의할 점 \n",
    "                                                        # 새로운 row은 하단에 append\n",
    "                                                        # 어떠한 row도 삭제하지 않는다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set, test_set = train_test_split(housing, test_size=0.2, random_state=42) # scikit-learn 이용해 train, test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "housing[\"median_income\"].hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "housing[\"income_cat\"] = np.ceil(housing[\"median_income\"] / 1.5) # np.ceil(k) => k 보다 크거나 같은 정수 반환 <=> np.floor(k)\n",
    "housing[\"income_cat\"].where(housing[\"income_cat\"] < 5, 5.0, inplace=True) # 데이터 상한선을 5로 설정 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42) # n_split : train/test split 몇 번 할 건지\n",
    "                                                                           # n_split = 1이므로 for loop 1번, 즉 단순 split\n",
    "for train_index, test_index in split.split(housing, housing[\"income_cat\"]): # housing['income_cat] 에 따라 stratify\n",
    "    strat_train_set = housing.loc[train_index]\n",
    "    strat_test_set = housing.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "housing[\"income_cat\"].value_counts() / len(housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for set_ in (strat_train_set, strat_test_set):\n",
    "    set_.drop(\"income_cat\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discover and Visualize the Data to Gain Insights <a id='ch3'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "housing = strat_train_set.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Visualizing Geographical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "housing.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "housing.plot(kind='scatter', x='longitude', y='latitude', alpha=0.1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.4,\n",
    "    s=housing[\"population\"]/100, label=\"population\", figsize=(10,7),\n",
    "    c=\"median_house_value\", cmap=plt.get_cmap(\"jet\"), colorbar=True,\n",
    "    sharex=False)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Looking for Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "link = \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/d4/Correlation_examples2.svg/1200px-Correlation_examples2.svg.png\"\n",
    "io.imshow(io.imread(link))\n",
    "io.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 방법1\n",
    "corr_matrix = housing.corr() \n",
    "corr_matrix[\"median_house_value\"].sort_values(ascending=False) # linear corrleation\n",
    "                                                               # nothing to do with slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 방법2\n",
    "attributes = [\"median_house_value\", \"median_income\", \"total_rooms\", \"housing_median_age\"]\n",
    "scatter_matrix(housing[attributes], figsize=(12, 8)); # main diagonal would be full of straight lines \n",
    "                                                      # if Pandas plotted each variable again itself\n",
    "                                                      # instead, pandas displays a histogram of each attribute (option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "housing.plot(kind=\"scatter\", x=\"median_income\", y=\"median_house_value\", alpha=0.1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Experimenting with Attribute Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "housing[\"rooms_per_household\"] = housing[\"total_rooms\"]/housing[\"households\"]\n",
    "housing[\"bedrooms_per_room\"] = housing[\"total_bedrooms\"]/housing[\"total_rooms\"]\n",
    "housing[\"population_per_household\"]=housing[\"population\"]/housing[\"households\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corr_matrix = housing.corr()\n",
    "corr_matrix[\"median_house_value\"].sort_values(ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
